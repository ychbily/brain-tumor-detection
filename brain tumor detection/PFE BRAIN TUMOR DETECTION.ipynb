{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d950894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The cv2 library in Python is the OpenCV (Open Source Computer Vision) library\n",
    "#.It is a library for computer vision programming and is used for a wide range of tasks such as image processing,\n",
    "#video analysis, face detection, object tracking,\n",
    "#etc. The library provides a vast collection of algorithms for image and video processing,\n",
    "#and has a large user community, which has contributed a lot of pre-trained models for various computer vision tasks.\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1df287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The os library in Python provides a way of using operating system \n",
    "#dependent functionality like reading or writing to the file system, \n",
    "#starting a new process or killing a process, reading or writing to the environment variables,\n",
    "#etc. It provides a portable way of using these functions across multiple platforms such as Windows, Mac, Linux, etc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a79fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source of dataset\n",
    "#https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection?resource=download\n",
    "\n",
    "images_dir = 'brain tumor/'\n",
    "NoTumor = os.listdir(images_dir + 'no/')\n",
    "print(NoTumor)\n",
    "len(NoTumor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = 'brain tumor/'\n",
    "YesTumor = os.listdir(images_dir+ 'yes/')\n",
    "YesTumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9aaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdcc0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[]\n",
    "label=[]\n",
    "size = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697098cd",
   "metadata": {},
   "source": [
    "# resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f16144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i, Name in enumerate(NoTumor):\n",
    "    if(Name.split('.')[1]=='jpg'):\n",
    "        image = cv2.imread(images_dir + 'no/' + Name)\n",
    "        image= Image.fromarray(image, 'RGB')\n",
    "        image= image.resize((size,size))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , Name in enumerate(YesTumor):\n",
    "    if(Name.split('.')[1]=='jpg'):\n",
    "        image = cv2.imread(images_dir + 'yes/' + Name)\n",
    "        image= Image.fromarray(image, 'RGB')\n",
    "        image= image.resize((size,size))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(dataset[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a362b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca8fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dataset,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030ecc4",
   "metadata": {},
   "source": [
    "# convert data into numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ddeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)\n",
    "label = np.array(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Image\", i+1)\n",
    "    print(dataset[i])\n",
    "    print(\"Label:\", label[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce8c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(dataset, label , test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347c4d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#\n",
    "#np.save('x_train.npy', x_train)\n",
    "#np.save('x_test.npy', x_test)\n",
    "#np.save('y_train.npy', y_train)\n",
    "#np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fe0459",
   "metadata": {},
   "source": [
    "# normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6244295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These lines of code import various functions from the keras.\n",
    "#layers module of the Keras library.\n",
    "#Keras is a high-level neural networks API,\n",
    "#written in Python and capable of running on top of TensorFlow.\n",
    "#The specific functions imported here are for building Convolutional Neural Network (ConvNet/CNN) models in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6501c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6228ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The statement from keras.models import Sequential is used to import the Sequential class from the Keras models module.\n",
    "#In Keras, the Sequential class is used to create a linear stack of layers,\n",
    "#which can be used to build a neural network model. A Sequential model is defined as a sequence of layers, \n",
    "#where each layer is added to the model one after the other.\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a20496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv2D: Implements the 2D convolution operation for spatial data,which is commonly used in image classification.\n",
    "#MaxPooling2D: Implements max pooling operation for spatial data, \n",
    "#which is used for down-sampling and reducing the spatial dimensions of the data while retaining the important features.\n",
    "\n",
    "    \n",
    "from keras.layers import Conv2D , MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aaa8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activation: Implements activation functions such as ReLU, sigmoid, etc., which are used to introduce non-linearity into the model.\n",
    "#Dropout: Implements the dropout regularization technique, which is used to prevent overfitting in the model by randomly dropping out some units during training.\n",
    "#Flatten: Implements the flattening operation, which is used to convert multi-dimensional arrays into single-dimensional arrays before passing them through fully connected layers.\n",
    "#Dense: Implements fully connected layers, which are used to make predictions based on the features learned by the ConvNet.\n",
    "\n",
    "from keras.layers import Activation ,Dropout,Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0804f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line of code normalizes the data in the x_test and x_train arrays along the column (axis=1) axis. \n",
    "#\"Normalizing\" refers to the process of scaling the values in\n",
    "#the array so that they have a unit norm (i.e., a length of 1 in a multi-dimensional space).\n",
    "#This is often done to preprocess the data before using it in machine learning models, \n",
    "#so that the variables are on a similar scale. \n",
    "#The normalize function is likely part of a library such as scikit-learn,\n",
    "#but without more information it's impossible to say for sure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088df3e3",
   "metadata": {},
   "source": [
    "# import data + models ++ build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e61458",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce75de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = normalize(x_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d653dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56473c3f",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb9c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code defines a neural network architecture in the Keras library.\n",
    "#The architecture consists of three layers: a convolutional layer, an activation layer, and a max pooling layer.\n",
    "\n",
    "#The first line defines the first layer in the network, a 2D convolutional layer. It has 32 filters of size (3, 3),\n",
    "#and the input shape is defined as (size, size, 3),\n",
    "#where size is a variable that specifies the size of the input image (presumably 200 in this case).\n",
    "\n",
    "#The second line adds a ReLU activation layer,\n",
    "#which applies the Rectified Linear Unit activation function to the output of the convolutional layer. \n",
    "#The ReLU activation function returns the input if it is positive, and returns 0 if it is negative.\n",
    "\n",
    "#The third line adds a max pooling layer,\n",
    "#which down-samples the spatial dimensions of the data.\n",
    "#The pool_size argument specifies the size of the max pooling window as (2,# 2).\n",
    "#This means that the max pooling layer will take the maximum value from each 2x2 region in the input\n",
    "#and produce a lower-resolution output with half the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f344b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "model.add(Conv2D(32,(3,3),input_shape=(size,size,3)))\n",
    "#2\n",
    "model.add(Activation('relu'))\n",
    "#3\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b14f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "model.add(Conv2D(32,(3,3),kernel_initializer='he_uniform'))\n",
    "#2\n",
    "model.add(Activation('relu'))\n",
    "#3\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "model.add(Conv2D(64,(3,3),kernel_initializer='he_uniform'))\n",
    "#2\n",
    "model.add(Activation('relu'))\n",
    "#3\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbafec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The idea behind adding multiple sets is to extract different features from the input images at different scales and resolutions,\n",
    "#which can improve the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80960be1",
   "metadata": {},
   "source": [
    "# Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbbdc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code defines the rest of the neural network architecture in the Keras library.\n",
    "#It consists of 5 additional layers: a flatten layer, two dense layers, a dropout layer, and an activation layer.\n",
    "\n",
    "#The first line adds a flatten layer,\n",
    "#which takes the multi-dimensional output from the previous layer and flattens it into a single dimension,\n",
    "#so it can be fed into the dense layers.\n",
    "\n",
    "#The second line adds a dense layer with 64 neurons, which is a fully connected layer.\n",
    "\n",
    "#The third line adds a ReLU activation layer,\n",
    "#which applies the Rectified Linear Unit activation function to the output of the dense layer.\n",
    "\n",
    "#The fourth line adds a dropout layer with a rate of 0.5,\n",
    "#which randomly drops out 50% of the neurons during each training iteration.\n",
    "#This is a regularization technique used to prevent overfitting in the model.\n",
    "\n",
    "#The fifth line adds a dense layer with 1 neuron, which will produce the final prediction.\n",
    "\n",
    "#The sixth line adds a sigmoid activation layer,\n",
    "#which applies the sigmoid activation function to the output of the dense layer.\n",
    "#This is often used for binary classification problems, where the output should be a value between 0 and 1,\n",
    "#indicating the probability of belonging to one class or another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464a748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'relu' is being used to introduce non-linearity in the convolutional and dense layers,\n",
    "#while 'sigmoid' is being used to produce the binary classification output.\n",
    "\n",
    "#1\n",
    "model.add(Flatten())\n",
    "#2\n",
    "model.add(Dense(64))\n",
    "#3\n",
    "model.add(Activation('relu'))\n",
    "#4\n",
    "model.add(Dropout(0.5))\n",
    "#5\n",
    "model.add(Dense(1)) #why 1 becaus we have only two folders of data yes and no so 0 and 1.\n",
    "#6\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line of code compiles the neural network model defined in the previous steps. \n",
    "#It sets the loss function, optimization algorithm, and evaluation metrics for the model.\n",
    "\n",
    "#loss='binary_crossentropy' sets the loss function for the model. \n",
    "#This is the common choice for binary classification problems,\n",
    "#where the target values are binary (0 or 1).\n",
    "#The binary cross-entropy loss measures the dissimilarity between the predicted probability distribution\n",
    "#and the true distribution.\n",
    "\n",
    "#optimizer='adam' sets the optimization algorithm used to update the model weights during training.\n",
    "#Adam is a widely used optimization algorithm that adaptively changes the learning rate \n",
    "#for each weight based on the historical gradient information.\n",
    "\n",
    "#metrics=['accuracy'] specifies the metrics to be used to evaluate the performance of the model. \n",
    "#In this case, the accuracy metric is used, which calculates the fraction of correct predictions made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d7a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b0cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81385c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line of code fits the compiled Keras model to the training data.\n",
    "#x_train and y_train are the training data and labels, respectively.\n",
    "\n",
    "#batch_size=16 specifies the number of samples to be used in each update of the model weights during training.\n",
    "#In this case, the model will update its weights after every 16 samples.\n",
    "\n",
    "#verbose=1 specifies the verbosity level of the training output. \n",
    "#1 means that the progress bar will be displayed during training.\n",
    "\n",
    "#epochs=10 specifies the number of times to go through the entire training dataset during training.\n",
    "\n",
    "#validation_data=(x_test, y_test) specifies the validation data and labels to be used for evaluating the model after each epoch.\n",
    "#This helps to track the performance of the model during training and detect overfitting.\n",
    "\n",
    "#shuffle=False specifies whether or not to shuffle the training data before each epoch.\n",
    "#If False, the data will be used in the order it was passed to fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be1a4d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train, batch_size=16,\n",
    "          verbose=1, epochs=20,\n",
    "          validation_data=(x_test,y_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70628cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line of code saves the trained machine learning model as an .h5 file. .h5\n",
    "#is a file format for storing large amounts of numerical data. \n",
    "#The h5 in BrainTumor.h5 refers to the Hierarchical Data Format version 5,\n",
    "#which is a popular file format for storing large datasets in machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('BrainTumorDetection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa391a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sources\n",
    "#https://www.nature.com/articles/s41598-022-05572-6\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "#https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9468505/\n",
    "#https://www.youtube.com/watch?v=7MceDfpnP8k&t=22s\n",
    "#https://keras.io/api/layers/convolution_layers/convolution2d/\n",
    "#https://keras.io/api/layers/pooling_layers/max_pooling2d/\n",
    "#https://keras.io/api/layers/core_layers/dense/\n",
    "#https://towardsdatascience.com/everything-you-need-to-know-about-activation-functions-in-deep-learning-models-84ba9f82c253\n",
    "#https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening\n",
    "#https://machinelearningmastery.com/using-activation-functions-in-deep-learning-models/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
